{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97c934c7",
   "metadata": {},
   "source": [
    "# ML Pipeline for Trading Bot\n",
    "\n",
    "This notebook provides a runnable skeleton ML pipeline for a trading bot. It includes: data loading, EDA, preprocessing, feature engineering, labeling, a simple model training example (sklearn), and a minimal backtester for signal evaluation.\n",
    "\n",
    "Notes:\n",
    "- This notebook is designed to be a starting point.\n",
    "- It uses CSVs in the `data/` folder in this workspace. Update `DATA_PATH` if needed.\n",
    "- After exploration, you can swap the model with LightGBM/XGBoost or LSTM-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c9dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install minimal packages if running in a fresh environment (uncomment to run)\n",
    "# !pip install -q pandas numpy scikit-learn matplotlib mplfinance ta lightgbm\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e15b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- DATA PATH: automatically find a CSV in the workspace data/ folder ----\n",
    "import glob\n",
    "WORKDIR = '/workspaces/POC_Safem0de_IS'\n",
    "data_dir = os.path.join(WORKDIR, 'data') if os.path.isdir(os.path.join(WORKDIR, 'data')) else os.path.join(os.getcwd(), 'data')\n",
    "csv_files = sorted(glob.glob(os.path.join(data_dir, '*.csv'))) if os.path.isdir(data_dir) else []\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f'No CSV files found in data directory: {data_dir}. Please add CSVs to the data/ folder or update DATA_PATH.')\n",
    "\n",
    "print('Found data files:')\n",
    "for i,f in enumerate(csv_files):\n",
    "    print(i, '-', f)\n",
    "\n",
    "# Default: pick the first CSV. You can change this to csv_files[n] to select another file.\n",
    "DATA_PATH = csv_files[0]\n",
    "print('Loading', DATA_PATH)\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# standardize column names if needed\n",
    "if len(df.columns) >= 6:\n",
    "    df.columns = ['datetime','open','high','low','close','volume'] + list(df.columns[6:])\n",
    "\n",
    "# parse datetime and sort\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df = df.sort_values('datetime').reset_index(drop=True)\n",
    "df.set_index('datetime', inplace=True)\n",
    "\n",
    "print('shape', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98db380",
   "metadata": {},
   "source": [
    "## Quick EDA\n",
    "Check data ranges and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcf61db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print('Missing per column:', df.isna().mean())\n",
    "\n",
    "# Basic plot of close price (last 500 points)\n",
    "_ = df['close'].iloc[-500:].plot(title='Close (last 500 points)', figsize=(12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271fb2b8",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Create a few robust features: returns, moving averages, vol, and a simple RSI implementation (no external `ta` required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d43603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_basic_features(df):\n",
    "    x = df.copy()\n",
    "    # returns\n",
    "    x['ret_1'] = x['close'].pct_change(1)\n",
    "    x['ret_3'] = x['close'].pct_change(3)\n",
    "    x['ret_24'] = x['close'].pct_change(24)\n",
    "    # moving averages\n",
    "    x['ma_5'] = x['close'].rolling(5).mean()\n",
    "    x['ma_20'] = x['close'].rolling(20).mean()\n",
    "    x['ma_50'] = x['close'].rolling(50).mean()\n",
    "    x['ema_12'] = x['close'].ewm(span=12, adjust=False).mean()\n",
    "    x['ema_26'] = x['close'].ewm(span=26, adjust=False).mean()\n",
    "    # momentum / volatility\n",
    "    x['std_20'] = x['close'].rolling(20).std()\n",
    "    x['range'] = x['high'] - x['low']\n",
    "    x['vol'] = x['volume']\n",
    "    # simple RSI implementation\n",
    "    delta = x['close'].diff()\n",
    "    up = delta.clip(lower=0)\n",
    "    down = -1 * delta.clip(upper=0)\n",
    "    roll_up = up.rolling(14).mean()\n",
    "    roll_down = down.rolling(14).mean()\n",
    "    rs = roll_up / roll_down\n",
    "    x['rsi14'] = 100 - (100 / (1 + rs))\n",
    "    return x.dropna()\n",
    "\n",
    "df_feat = add_basic_features(df)\n",
    "print('after features:', df_feat.shape)\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6501884a",
   "metadata": {},
   "source": [
    "## Labeling (supervised target)\n",
    "We'll create a simple classification target: whether price returns over the next N periods exceed a threshold. This is a straightforward target for a signal-based bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e3e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(df, horizon=6, ret_threshold=0.001):\n",
    "    # horizon: lookahead periods, ret_threshold: threshold for 'up'\n",
    "    x = df.copy()\n",
    "    x['future_close'] = x['close'].shift(-horizon)\n",
    "    x['future_ret'] = x['future_close'] / x['close'] - 1\n",
    "    # multiclass or binary: -1 bearish, 0 neutral, 1 bullish\n",
    "    x['label'] = 0\n",
    "    x.loc[x['future_ret'] > ret_threshold, 'label'] = 1\n",
    "    x.loc[x['future_ret'] < -ret_threshold, 'label'] = -1\n",
    "    return x.dropna()\n",
    "\n",
    "df_labeled = create_labels(df_feat, horizon=12, ret_threshold=0.002)  # e.g., 12 hours ahead for H1 data\n",
    "print('labeled shape:', df_labeled.shape)\n",
    "df_labeled['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d36a194",
   "metadata": {},
   "source": [
    "## Train / Test split (time-series aware) and feature selection\n",
    "We'll use a simple time split to avoid leakage. Then train a RandomForest classifier as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965509c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features (drop price-derived columns we don't want as direct features)\n",
    "drop_cols = ['future_close','future_ret','label']\n",
    "features = [c for c in df_labeled.columns if c not in drop_cols and c in ['ret_1','ret_3','ret_24','ma_5','ma_20','ma_50','ema_12','ema_26','std_20','rsi14']]\n",
    "X = df_labeled[features].copy()\n",
    "y = df_labeled['label'].copy()\n",
    "\n",
    "# time split: last 20% as test\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\n",
    "y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
    "\n",
    "print('X_train, X_test shapes', X_train.shape, X_test.shape)\n",
    "\n",
    "# baseline model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('Accuracy:', accuracy_score(y_test, pred))\n",
    "\n",
    "# cross-validated time series score (quick)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "scores = cross_val_score(clf, X, y, cv=tscv, scoring='accuracy', n_jobs=-1)\n",
    "print('CV accuracy (TimeSeriesSplit):', scores, 'mean=', np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72daa5b9",
   "metadata": {},
   "source": [
    "## Simple Backtester (Signal-based)\n",
    "Convert model predictions to position signals and simulate P&L simply (no transaction costs by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b424cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_signals(df_indexed, signals, price_col='close', hold_period=12, transaction_cost=0.0):\n",
    "    # df_indexed: original df indexed by datetime aligned to signals array index\n",
    "    # signals: array-like of -1/0/1 signals aligned with df_indexed rows\n",
    "    res = pd.DataFrame(index=df_indexed.index)\n",
    "    res['signal'] = signals\n",
    "    res['price'] = df_indexed[price_col]\n",
    "    # shift signal so we enter at next bar open (approx)\n",
    "    res['entry_price'] = res['price'].shift(-1)\n",
    "    res['exit_price'] = res['price'].shift(-hold_period)\n",
    "    # compute return per trade (exit/entry - 1) * sign - cost\n",
    "    res['trade_ret'] = (res['exit_price'] / res['entry_price'] - 1) * res['signal'] - transaction_cost\n",
    "    # cumulative simple equity curve ignoring position sizing\n",
    "    res['strategy_equity'] = (1 + res['trade_ret'].fillna(0)).cumprod()\n",
    "    res['market_equity'] = (1 + res['price'].pct_change().fillna(0)).cumprod()\n",
    "    return res\n",
    "\n",
    "# produce model signals on test set (map predictions -1/0/1)\n",
    "pred_proba = clf.predict(X_test)  # already -1/0/1 labels from classifier\n",
    "# align with df_labeled index for test slice\n",
    "test_index = X_test.index\n",
    "signals = pd.Series(pred_proba, index=test_index)\n",
    "bt = backtest_signals(df.loc[test_index], signals, hold_period=12, transaction_cost=0.000)\n",
    "\n",
    "print('Strategy final equity (relative):', bt['strategy_equity'].iloc[-1])\n",
    "print('Market final equity (relative):', bt['market_equity'].iloc[-1])\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(bt['strategy_equity'], label='Strategy')\n",
    "plt.plot(bt['market_equity'], label='Market')\n",
    "plt.legend()\n",
    "plt.title('Equity Curves (Test Period)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7eb80b",
   "metadata": {},
   "source": [
    "## Next steps / Recommendations\n",
    "- Replace RandomForest baseline with LightGBM or XGBoost for tabular features for speed and better performance.\n",
    "- Implement walk-forward validation and hyperparameter tuning (Bayesian or Optuna).\n",
    "- Add transaction costs, slippage, and leverage to the backtester.\n",
    "- For sequence models: build LSTM/CNN models earlier observed in `POC_*` notebooks and compare.\n",
    "- Add a paper-trade adapter to a broker API (ccxt for crypto, OANDA/IB for FX).\n",
    "- Create CI tests for data loading and feature functions."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
