{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßπ ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 2.2: Data Cleaning - ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "\n",
    "## üé≠ ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡∏ô‡∏±‡∏Å‡∏™‡∏∑‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "\n",
    "‡∏à‡∏≤‡∏Å‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ 500 ‡∏Ñ‡∏ô‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏ï‡πà‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡πá‡∏Ñ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á...\n",
    "\n",
    "üò± **‡∏û‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤!**\n",
    "- ‡∏ö‡∏≤‡∏á‡∏Ñ‡∏ô‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏≠‡∏Å **‡∏≠‡∏≤‡∏¢‡∏∏** (Missing Values)\n",
    "- ‡∏°‡∏µ‡∏Ñ‡∏ô‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏≠‡∏≤‡∏¢‡∏∏ **150 ‡∏õ‡∏µ**! (Outliers)\n",
    "- ‡∏°‡∏µ‡∏Ñ‡∏ô‡∏Å‡∏£‡∏≠‡∏Å Income ‡πÄ‡∏õ‡πá‡∏ô **-50000** (Inconsistencies)\n",
    "\n",
    "‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏Å‡∏õ‡∏£‡∏Å‡∏ô‡∏µ‡πâ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ‚Üí ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ú‡∏¥‡∏î!\n",
    "\n",
    "**‡∏°‡∏≤‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏±‡∏ô‡πÄ‡∏ñ‡∏≠‡∏∞!** üßπ‚ú®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "print(\"‚úÖ Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (Dirty Data)\n",
    "\n",
    "‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏à‡∏á‡πÉ‡∏à‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏Å‡∏ï‡∏¥\n",
    "n = 500\n",
    "data = {\n",
    "    'CustomerID': [f'C{str(i).zfill(4)}' for i in range(1, n+1)],\n",
    "    'Age': np.random.randint(18, 65, n).astype(float),\n",
    "    'Income': np.random.randint(25000, 120000, n).astype(float),\n",
    "    'SpendingScore': np.random.randint(1, 100, n).astype(float),\n",
    "    'PurchaseCount': np.random.randint(1, 50, n).astype(float)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ========================================\n",
    "# üî• ‡∏à‡∏á‡πÉ‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏Å‡∏õ‡∏£‡∏Å!\n",
    "# ========================================\n",
    "\n",
    "# 1. Missing Values (15% ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)\n",
    "missing_indices = np.random.choice(df.index, size=int(0.15*n), replace=False)\n",
    "df.loc[missing_indices[:25], 'Age'] = np.nan\n",
    "df.loc[missing_indices[25:50], 'Income'] = np.nan\n",
    "df.loc[missing_indices[50:], 'SpendingScore'] = np.nan\n",
    "\n",
    "# 2. Outliers (‡∏≠‡∏≤‡∏¢‡∏∏‡πÅ‡∏õ‡∏•‡∏Å‡πÜ ‡πÅ‡∏•‡∏∞ Income ‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥)\n",
    "outlier_indices = np.random.choice(df.index, size=15, replace=False)\n",
    "df.loc[outlier_indices[:5], 'Age'] = [150, 5, 200, 0, 250]  # ‡∏≠‡∏≤‡∏¢‡∏∏‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥\n",
    "df.loc[outlier_indices[5:10], 'Income'] = [500000, 600000, 750000, 1000000, 850000]  # ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏™‡∏π‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥\n",
    "df.loc[outlier_indices[10:], 'SpendingScore'] = [150, 200, -50, 300, 999]  # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥\n",
    "\n",
    "# 3. Inconsistencies (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•)\n",
    "inconsistent_indices = np.random.choice(df.index, size=10, replace=False)\n",
    "df.loc[inconsistent_indices[:5], 'Income'] = [-10000, -50000, -25000, 0, -1000]  # ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏ï‡∏¥‡∏î‡∏•‡∏ö\n",
    "df.loc[inconsistent_indices[5:], 'PurchaseCount'] = [-5, -10, 0, -2, -8]  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ã‡∏∑‡πâ‡∏≠‡∏ï‡∏¥‡∏î‡∏•‡∏ö\n",
    "\n",
    "print(\"üíÄ Created DIRTY data with problems:\")\n",
    "print(f\"   Total records: {len(df)}\")\n",
    "print(f\"   ‚úì Missing values\")\n",
    "print(f\"   ‚úì Outliers\")\n",
    "print(f\"   ‚úì Inconsistencies\")\n",
    "print(\"\\nLet's investigate! üîç\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîç Part 1: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Missing Values\n",
    "\n",
    "### Missing Values ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?\n",
    "- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ (NaN, None, null)\n",
    "- ‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å: ‡∏•‡∏∑‡∏°‡∏Å‡∏£‡∏≠‡∏Å, ‡∏£‡∏∞‡∏ö‡∏ö error, ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö\n",
    "\n",
    "### ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£?\n",
    "- ‡πÇ‡∏°‡πÄ‡∏î‡∏• ML ‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö NaN ‚Üí ‡∏à‡∏∞ error!\n",
    "- Missing ‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡πà‡∏° ‚Üí ‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Missing Values\n",
    "print(\"‚ùì Missing Values Check:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "missing_count = df.isnull().sum()\n",
    "missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_count.index,\n",
    "    'Missing Count': missing_count.values,\n",
    "    'Percentage': missing_percent.values\n",
    "})\n",
    "\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "print(f\"\\nüìä Total missing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Missing Values\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Heatmap\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(df.isnull(), cbar=True, yticklabels=False, cmap='viridis')\n",
    "plt.title('Missing Values Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Rows')\n",
    "\n",
    "# Bar chart\n",
    "plt.subplot(1, 2, 2)\n",
    "missing_data = df.isnull().sum()[df.isnull().sum() > 0]\n",
    "missing_data.plot(kind='bar', color='coral')\n",
    "plt.title('Missing Values per Column', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Column')\n",
    "plt.ylabel('Number of Missing Values')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Missing Values\n",
    "\n",
    "print(\"üõ†Ô∏è Solutions for Missing Values:\\n\")\n",
    "\n",
    "# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡∏•‡∏ö‡∏ó‡∏¥‡πâ‡∏á (Drop)\n",
    "df_dropped = df.dropna()\n",
    "print(f\"1Ô∏è‚É£ Drop rows with NaN:\")\n",
    "print(f\"   Before: {len(df)} rows\")\n",
    "print(f\"   After: {len(df_dropped)} rows\")\n",
    "print(f\"   Lost: {len(df) - len(df_dropped)} rows ({((len(df) - len(df_dropped))/len(df)*100):.1f}%)\")\n",
    "print(f\"   ‚ö†Ô∏è Use when: Missing < 5% of data\\n\")\n",
    "\n",
    "# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡∏Å‡∏£‡∏≠‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (Mean)\n",
    "df_mean = df.copy()\n",
    "df_mean['Age'].fillna(df_mean['Age'].mean(), inplace=True)\n",
    "df_mean['Income'].fillna(df_mean['Income'].mean(), inplace=True)\n",
    "df_mean['SpendingScore'].fillna(df_mean['SpendingScore'].mean(), inplace=True)\n",
    "print(f\"2Ô∏è‚É£ Fill with Mean:\")\n",
    "print(f\"   Age mean: {df['Age'].mean():.1f}\")\n",
    "print(f\"   ‚úì Good for: Normal distribution\\n\")\n",
    "\n",
    "# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: ‡∏Å‡∏£‡∏≠‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏≤‡∏á (Median)\n",
    "df_median = df.copy()\n",
    "df_median['Age'].fillna(df_median['Age'].median(), inplace=True)\n",
    "df_median['Income'].fillna(df_median['Income'].median(), inplace=True)\n",
    "df_median['SpendingScore'].fillna(df_median['SpendingScore'].median(), inplace=True)\n",
    "print(f\"3Ô∏è‚É£ Fill with Median:\")\n",
    "print(f\"   Age median: {df['Age'].median():.1f}\")\n",
    "print(f\"   ‚úì Good for: Data with outliers\\n\")\n",
    "\n",
    "# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 4: ‡∏Å‡∏£‡∏≠‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏ö‡πà‡∏≠‡∏¢‡∏™‡∏∏‡∏î (Mode)\n",
    "df_mode = df.copy()\n",
    "df_mode['SpendingScore'].fillna(df_mode['SpendingScore'].mode()[0], inplace=True)\n",
    "print(f\"4Ô∏è‚É£ Fill with Mode:\")\n",
    "print(f\"   SpendingScore mode: {df['SpendingScore'].mode()[0]:.1f}\")\n",
    "print(f\"   ‚úì Good for: Categorical data\\n\")\n",
    "\n",
    "# ‡πÉ‡∏ä‡πâ Median (‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏µ outliers)\n",
    "df_clean = df_median.copy()\n",
    "print(\"‚úÖ We'll use MEDIAN filling (best for data with outliers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Part 2: ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö Outliers\n",
    "\n",
    "### Outliers ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?\n",
    "- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà **‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏°‡∏≤‡∏Å** ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∑‡πà‡∏ô\n",
    "- ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏≠‡∏≤‡∏¢‡∏∏ 200 ‡∏õ‡∏µ, ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ 10 ‡∏•‡πâ‡∏≤‡∏ô/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ)\n",
    "\n",
    "### ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£?\n",
    "- Outliers ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô\n",
    "- ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ú‡∏¥‡∏î ‚Üí Prediction ‡πÑ‡∏°‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥\n",
    "\n",
    "### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏´‡∏≤ Outliers:\n",
    "1. **Z-Score** - ‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Å‡∏µ‡πà standard deviation\n",
    "2. **IQR (Interquartile Range)** - ‡πÉ‡∏ä‡πâ‡∏ä‡πà‡∏ß‡∏á Q1-Q3\n",
    "3. **Visualization** - Box plot, Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Outliers with Box Plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Age\n",
    "axes[0, 0].boxplot(df_clean['Age'].dropna(), vert=True)\n",
    "axes[0, 0].set_title('Age Distribution (Before Cleaning)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Age')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Income\n",
    "axes[0, 1].boxplot(df_clean['Income'].dropna(), vert=True)\n",
    "axes[0, 1].set_title('Income Distribution (Before Cleaning)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Income ($)')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# SpendingScore\n",
    "axes[1, 0].boxplot(df_clean['SpendingScore'].dropna(), vert=True)\n",
    "axes[1, 0].set_title('Spending Score (Before Cleaning)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Score')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# PurchaseCount\n",
    "axes[1, 1].boxplot(df_clean['PurchaseCount'].dropna(), vert=True)\n",
    "axes[1, 1].set_title('Purchase Count (Before Cleaning)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üëÄ ‡πÄ‡∏´‡πá‡∏ô‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡πÑ‡∏´‡∏°? (‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å whiskers)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: Z-Score Method\n",
    "print(\"üî¨ Method 1: Z-Score Detection\")\n",
    "print(\"=\"*60)\n",
    "print(\"üìå Z-Score = (value - mean) / std\")\n",
    "print(\"üìå Outlier if |Z-Score| > 3\\n\")\n",
    "\n",
    "def detect_outliers_zscore(df, column, threshold=3):\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    z_scores = np.abs((df[column] - mean) / std)\n",
    "    outliers = df[z_scores > threshold]\n",
    "    return outliers, z_scores\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Age\n",
    "age_outliers, age_z = detect_outliers_zscore(df_clean, 'Age')\n",
    "print(f\"Age Outliers (Z-Score method): {len(age_outliers)} records\")\n",
    "print(f\"Examples:\")\n",
    "print(age_outliers[['CustomerID', 'Age']].head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: IQR Method (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥!)\n",
    "print(\"üìä Method 2: IQR (Interquartile Range) Detection\")\n",
    "print(\"=\"*60)\n",
    "print(\"üìå Q1 = 25th percentile\")\n",
    "print(\"üìå Q3 = 75th percentile\")\n",
    "print(\"üìå IQR = Q3 - Q1\")\n",
    "print(\"üìå Outlier if: value < Q1 - 1.5*IQR OR value > Q3 + 1.5*IQR\\n\")\n",
    "\n",
    "def detect_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    \n",
    "    print(f\"\\n{column}:\")\n",
    "    print(f\"   Q1: {Q1:.2f}\")\n",
    "    print(f\"   Q3: {Q3:.2f}\")\n",
    "    print(f\"   IQR: {IQR:.2f}\")\n",
    "    print(f\"   Valid range: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "    print(f\"   Outliers found: {len(outliers)}\")\n",
    "    \n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å column\n",
    "age_out_iqr, age_lower, age_upper = detect_outliers_iqr(df_clean, 'Age')\n",
    "income_out_iqr, income_lower, income_upper = detect_outliers_iqr(df_clean, 'Income')\n",
    "score_out_iqr, score_lower, score_upper = detect_outliers_iqr(df_clean, 'SpendingScore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÅ‡∏™‡∏î‡∏á Outliers ‡∏ó‡∏µ‡πà‡∏û‡∏ö\n",
    "print(\"\\nüö® Found Outliers:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìç Age Outliers:\")\n",
    "print(age_out_iqr[['CustomerID', 'Age']].sort_values('Age', ascending=False).head(10))\n",
    "\n",
    "print(\"\\nüí∞ Income Outliers:\")\n",
    "print(income_out_iqr[['CustomerID', 'Income']].sort_values('Income', ascending=False).head(10))\n",
    "\n",
    "print(\"\\nüìä Spending Score Outliers:\")\n",
    "print(score_out_iqr[['CustomerID', 'SpendingScore']].sort_values('SpendingScore', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Outliers\n",
    "print(\"üõ†Ô∏è Fixing Outliers:\\n\")\n",
    "\n",
    "df_no_outliers = df_clean.copy()\n",
    "\n",
    "# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡∏ï‡∏±‡∏î‡∏ó‡∏¥‡πâ‡∏á (Remove)\n",
    "print(\"Method A: Remove outliers\")\n",
    "print(f\"   Before: {len(df_no_outliers)} records\")\n",
    "\n",
    "# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: Cap/Clip (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥!)\n",
    "print(\"\\nMethod B: Cap outliers (Recommended) ‚úÖ\")\n",
    "print(\"   Replace values outside valid range with boundary values\\n\")\n",
    "\n",
    "# Cap Age\n",
    "df_no_outliers['Age'] = df_no_outliers['Age'].clip(lower=age_lower, upper=age_upper)\n",
    "print(f\"   Age capped to [{age_lower:.0f}, {age_upper:.0f}]\")\n",
    "\n",
    "# Cap Income\n",
    "df_no_outliers['Income'] = df_no_outliers['Income'].clip(lower=income_lower, upper=income_upper)\n",
    "print(f\"   Income capped to [{income_lower:.0f}, {income_upper:.0f}]\")\n",
    "\n",
    "# Cap SpendingScore\n",
    "df_no_outliers['SpendingScore'] = df_no_outliers['SpendingScore'].clip(lower=score_lower, upper=score_upper)\n",
    "print(f\"   SpendingScore capped to [{score_lower:.0f}, {score_upper:.0f}]\")\n",
    "\n",
    "print(f\"\\n‚úÖ Outliers fixed! Records maintained: {len(df_no_outliers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Part 3: ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Inconsistencies\n",
    "\n",
    "### Inconsistencies ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?\n",
    "- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà **‡πÑ‡∏°‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•** ‡∏ï‡∏≤‡∏° business logic\n",
    "\n",
    "### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:\n",
    "- ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ **‡∏ï‡∏¥‡∏î‡∏•‡∏ö** (‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ)\n",
    "- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ã‡∏∑‡πâ‡∏≠ **‡∏ï‡∏¥‡∏î‡∏•‡∏ö** (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ó‡∏≤‡∏á)\n",
    "- ‡∏≠‡∏≤‡∏¢‡∏∏ **0 ‡∏´‡∏£‡∏∑‡∏≠ 200 ‡∏õ‡∏µ** (‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥)\n",
    "- SpendingScore **> 100 ‡∏´‡∏£‡∏∑‡∏≠ < 0** (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏£‡∏≠‡∏¢‡∏π‡πà 0-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏´‡∏≤ Inconsistencies\n",
    "print(\"üîç Checking for Inconsistencies:\\n\")\n",
    "\n",
    "# 1. ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏ï‡∏¥‡∏î‡∏•‡∏ö‡∏´‡∏£‡∏∑‡∏≠ 0\n",
    "negative_income = df_no_outliers[df_no_outliers['Income'] <= 0]\n",
    "print(f\"1Ô∏è‚É£ Negative or Zero Income: {len(negative_income)} records\")\n",
    "if len(negative_income) > 0:\n",
    "    print(negative_income[['CustomerID', 'Income']].head())\n",
    "    print(\"   ‚ùå Problem: Income cannot be negative or zero!\\n\")\n",
    "\n",
    "# 2. ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ã‡∏∑‡πâ‡∏≠‡∏ï‡∏¥‡∏î‡∏•‡∏ö\n",
    "negative_purchase = df_no_outliers[df_no_outliers['PurchaseCount'] < 0]\n",
    "print(f\"2Ô∏è‚É£ Negative Purchase Count: {len(negative_purchase)} records\")\n",
    "if len(negative_purchase) > 0:\n",
    "    print(negative_purchase[['CustomerID', 'PurchaseCount']].head())\n",
    "    print(\"   ‚ùå Problem: Cannot have negative purchases!\\n\")\n",
    "\n",
    "# 3. ‡∏≠‡∏≤‡∏¢‡∏∏‡πÑ‡∏°‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•\n",
    "weird_age = df_no_outliers[(df_no_outliers['Age'] < 18) | (df_no_outliers['Age'] > 100)]\n",
    "print(f\"3Ô∏è‚É£ Unrealistic Age: {len(weird_age)} records\")\n",
    "if len(weird_age) > 0:\n",
    "    print(weird_age[['CustomerID', 'Age']].head())\n",
    "    print(\"   ‚ùå Problem: Age should be 18-100 for adult customers!\\n\")\n",
    "\n",
    "# 4. ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ô‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á 0-100\n",
    "weird_score = df_no_outliers[(df_no_outliers['SpendingScore'] < 0) | (df_no_outliers['SpendingScore'] > 100)]\n",
    "print(f\"4Ô∏è‚É£ Invalid Spending Score: {len(weird_score)} records\")\n",
    "if len(weird_score) > 0:\n",
    "    print(weird_score[['CustomerID', 'SpendingScore']].head())\n",
    "    print(\"   ‚ùå Problem: Score must be 0-100!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Inconsistencies\n",
    "print(\"üõ†Ô∏è Fixing Inconsistencies:\\n\")\n",
    "\n",
    "df_consistent = df_no_outliers.copy()\n",
    "\n",
    "# 1. ‡πÅ‡∏Å‡πâ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏ï‡∏¥‡∏î‡∏•‡∏ö ‚Üí ‡πÉ‡∏ä‡πâ Median\n",
    "median_income = df_consistent[df_consistent['Income'] > 0]['Income'].median()\n",
    "df_consistent.loc[df_consistent['Income'] <= 0, 'Income'] = median_income\n",
    "print(f\"‚úÖ Fixed negative income ‚Üí replaced with median: ${median_income:.0f}\")\n",
    "\n",
    "# 2. ‡πÅ‡∏Å‡πâ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ã‡∏∑‡πâ‡∏≠‡∏ï‡∏¥‡∏î‡∏•‡∏ö ‚Üí ‡πÉ‡∏ä‡πâ 1 (‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥)\n",
    "df_consistent.loc[df_consistent['PurchaseCount'] < 0, 'PurchaseCount'] = 1\n",
    "print(f\"‚úÖ Fixed negative purchases ‚Üí replaced with minimum: 1\")\n",
    "\n",
    "# 3. ‡πÅ‡∏Å‡πâ‡∏≠‡∏≤‡∏¢‡∏∏‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥ ‚Üí ‡πÉ‡∏ä‡πâ Median\n",
    "median_age = df_consistent[(df_consistent['Age'] >= 18) & (df_consistent['Age'] <= 100)]['Age'].median()\n",
    "df_consistent.loc[(df_consistent['Age'] < 18) | (df_consistent['Age'] > 100), 'Age'] = median_age\n",
    "print(f\"‚úÖ Fixed unrealistic age ‚Üí replaced with median: {median_age:.0f}\")\n",
    "\n",
    "# 4. ‡πÅ‡∏Å‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ô‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á ‚Üí Clip to 0-100\n",
    "df_consistent['SpendingScore'] = df_consistent['SpendingScore'].clip(0, 100)\n",
    "print(f\"‚úÖ Fixed spending score ‚Üí clipped to [0, 100]\")\n",
    "\n",
    "print(f\"\\nüéâ All inconsistencies fixed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç\n",
    "print(\"üîç Verification after cleaning:\\n\")\n",
    "\n",
    "print(\"Age:\")\n",
    "print(f\"   Min: {df_consistent['Age'].min():.1f}\")\n",
    "print(f\"   Max: {df_consistent['Age'].max():.1f}\")\n",
    "print(f\"   Mean: {df_consistent['Age'].mean():.1f}\\n\")\n",
    "\n",
    "print(\"Income:\")\n",
    "print(f\"   Min: ${df_consistent['Income'].min():.0f}\")\n",
    "print(f\"   Max: ${df_consistent['Income'].max():.0f}\")\n",
    "print(f\"   Mean: ${df_consistent['Income'].mean():.0f}\\n\")\n",
    "\n",
    "print(\"SpendingScore:\")\n",
    "print(f\"   Min: {df_consistent['SpendingScore'].min():.1f}\")\n",
    "print(f\"   Max: {df_consistent['SpendingScore'].max():.1f}\")\n",
    "print(f\"   Mean: {df_consistent['SpendingScore'].mean():.1f}\\n\")\n",
    "\n",
    "print(\"PurchaseCount:\")\n",
    "print(f\"   Min: {df_consistent['PurchaseCount'].min():.0f}\")\n",
    "print(f\"   Max: {df_consistent['PurchaseCount'].max():.0f}\")\n",
    "print(f\"   Mean: {df_consistent['PurchaseCount'].mean():.1f}\\n\")\n",
    "\n",
    "print(\"‚úÖ All values are now in valid ranges!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Before vs After Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏á\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Age\n",
    "axes[0, 0].hist(df['Age'].dropna(), bins=30, alpha=0.7, color='red', label='Before', edgecolor='black')\n",
    "axes[0, 0].set_title('Age - Before Cleaning', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Age')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "axes[1, 0].hist(df_consistent['Age'], bins=30, alpha=0.7, color='green', label='After', edgecolor='black')\n",
    "axes[1, 0].set_title('Age - After Cleaning', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Age')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Income\n",
    "axes[0, 1].hist(df['Income'].dropna(), bins=30, alpha=0.7, color='red', label='Before', edgecolor='black')\n",
    "axes[0, 1].set_title('Income - Before Cleaning', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Income ($)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "axes[1, 1].hist(df_consistent['Income'], bins=30, alpha=0.7, color='green', label='After', edgecolor='black')\n",
    "axes[1, 1].set_title('Income - After Cleaning', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Income ($)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "# SpendingScore\n",
    "axes[0, 2].hist(df['SpendingScore'].dropna(), bins=30, alpha=0.7, color='red', label='Before', edgecolor='black')\n",
    "axes[0, 2].set_title('Spending Score - Before', fontsize=12, fontweight='bold')\n",
    "axes[0, 2].set_xlabel('Score')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "axes[0, 2].legend()\n",
    "\n",
    "axes[1, 2].hist(df_consistent['SpendingScore'], bins=30, alpha=0.7, color='green', label='After', edgecolor='black')\n",
    "axes[1, 2].set_title('Spending Score - After', fontsize=12, fontweight='bold')\n",
    "axes[1, 2].set_xlabel('Score')\n",
    "axes[1, 2].set_ylabel('Frequency')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üëÄ ‡πÄ‡∏´‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡πÑ‡∏´‡∏°? ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏î‡∏π‡∏õ‡∏Å‡∏ï‡∏¥‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß\n",
    "df_consistent.to_csv('customer_data_clean.csv', index=False)\n",
    "print(\"üíæ Saved clean data to 'customer_data_clean.csv'\")\n",
    "print(f\"\\nüìä Final Statistics:\")\n",
    "print(f\"   Total records: {len(df_consistent)}\")\n",
    "print(f\"   Missing values: {df_consistent.isnull().sum().sum()}\")\n",
    "print(f\"   All data is now clean and ready for ML! ‚ú®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù ‡∏™‡∏£‡∏∏‡∏õ: Data Cleaning\n",
    "\n",
    "### üéØ ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ:\n",
    "\n",
    "#### 1. **Missing Values**\n",
    "- **‡∏´‡∏≤:** `df.isnull().sum()`\n",
    "- **‡πÅ‡∏Å‡πâ:**\n",
    "  - Drop: `df.dropna()`\n",
    "  - Fill with mean: `df.fillna(df.mean())`\n",
    "  - Fill with median: `df.fillna(df.median())` ‚Üê **‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ñ‡πâ‡∏≤‡∏°‡∏µ outliers**\n",
    "  - Fill with mode: `df.fillna(df.mode()[0])`\n",
    "\n",
    "#### 2. **Outliers**\n",
    "- **‡∏´‡∏≤:**\n",
    "  - Z-Score: `|Z| > 3`\n",
    "  - IQR: `Q1 - 1.5*IQR` ‡∏ñ‡∏∂‡∏á `Q3 + 1.5*IQR` ‚Üê **‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥**\n",
    "- **‡πÅ‡∏Å‡πâ:**\n",
    "  - Remove: ‡∏•‡∏ö‡∏ó‡∏¥‡πâ‡∏á\n",
    "  - Cap/Clip: ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡πà‡∏≤ ‚Üê **‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)**\n",
    "\n",
    "#### 3. **Inconsistencies**\n",
    "- **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**\n",
    "  - ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏ï‡∏¥‡∏î‡∏•‡∏ö ‚Üí ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ\n",
    "  - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ã‡∏∑‡πâ‡∏≠‡∏ï‡∏¥‡∏î‡∏•‡∏ö ‚Üí ‡∏ú‡∏¥‡∏î‡∏ï‡∏£‡∏£‡∏Å‡∏∞\n",
    "  - ‡∏≠‡∏≤‡∏¢‡∏∏ 0 ‡∏´‡∏£‡∏∑‡∏≠ 200 ‚Üí ‡πÑ‡∏°‡πà‡∏™‡∏°‡∏à‡∏£‡∏¥‡∏á\n",
    "- **‡πÅ‡∏Å‡πâ:**\n",
    "  - ‡πÉ‡∏ä‡πâ business logic ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\n",
    "  - Replace ‡∏î‡πâ‡∏ß‡∏¢ median/mean/mode\n",
    "  - Clip ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°\n",
    "\n",
    "### üöÄ Next Step:\n",
    "\n",
    "‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß! ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•...\n",
    "\n",
    "üëâ [‡∏ö‡∏ó‡∏ï‡πà‡∏≠‡πÑ‡∏õ: Data Transformation (Normalization & Standardization)](03_data_transformation.ipynb)\n",
    "\n",
    "‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô scale ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üí° Key Takeaways\n",
    "\n",
    "### ‚úÖ Golden Rules:\n",
    "\n",
    "1. **Always check data quality first!**\n",
    "   - Missing values?\n",
    "   - Outliers?\n",
    "   - Inconsistencies?\n",
    "\n",
    "2. **Visualize before and after cleaning**\n",
    "   - Box plots for outliers\n",
    "   - Histograms for distribution\n",
    "   - Heatmaps for missing values\n",
    "\n",
    "3. **Use domain knowledge**\n",
    "   - ‡∏Ñ‡πà‡∏≤‡∏≠‡∏∞‡πÑ‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ?\n",
    "   - ‡∏Ñ‡πà‡∏≤‡∏≠‡∏∞‡πÑ‡∏£‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥?\n",
    "   - ‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£?\n",
    "\n",
    "4. **Document your cleaning steps**\n",
    "   - ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á?\n",
    "   - ‡∏ó‡∏≥‡πÑ‡∏°‡∏ñ‡∏∂‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡∏ô‡∏±‡πâ‡∏ô?\n",
    "   - ‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏±‡∏á‡πÑ‡∏á?\n",
    "\n",
    "### ‚ö†Ô∏è Common Mistakes:\n",
    "\n",
    "‚ùå Drop ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏¥‡πâ‡∏á‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (‡πÄ‡∏™‡∏µ‡∏¢ information)\n",
    "‚ùå ‡πÉ‡∏ä‡πâ mean fill ‡∏ó‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ outliers ‡πÄ‡∏¢‡∏≠‡∏∞\n",
    "‚ùå ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö business logic\n",
    "‚ùå Clean ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà visualize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
